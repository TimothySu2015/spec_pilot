# Story 2.5: CLI 端到端測試涵蓋核心流程

## Status

Draft

## Story

**As a** 開發者,
**I want** 自動化驗證 CLI 完整流程,
**so that** 新增功能不會破壞既有行為。

## Acceptance Criteria

1. 建立整合測試，模擬載入規格、解析流程、執行、驗證、輸出報表。
2. 測試涵蓋成功與失敗案例，覆蓋 CLI 與 MCP（含 JSON-RPC 錯誤格式）。
3. 測試納入 CI，自動檢查 NFR2 規定時間。
4. 測試資料放在 `specs/`、`flows/`、`reports/` 範例目錄。

## Tasks / Subtasks

- [ ] 建立 CLI 端對端測試框架 (AC: 1, 4)
  - [ ] 在 `tests/e2e/` 建立測試目錄與結構
  - [ ] 設定 Vitest 端對端測試配置
  - [ ] 準備測試用 OpenAPI 規格與 Flow YAML 於 `specs/` 與 `flows/`
  - [ ] 建立測試輔助工具（啟動 CLI、清理暫存檔案等）
  - [ ] 使用 execa 或類似工具執行 CLI 指令並捕獲輸出
  - [ ] 在根目錄 `package.json` 新增 devDependency `execa`（或明確指定等效執行工具）

- [ ] 實作成功流程的端對端測試 (AC: 1, 2)
  - [ ] 測試完整 CLI 執行：`specpilot run --spec --flow --baseUrl`
  - [ ] 驗證規格載入與解析成功
  - [ ] 驗證流程解析與執行成功
  - [ ] 驗證步驟執行、HTTP 呼叫與驗證
  - [ ] 驗證報表檔案產生於正確位置 (`reports/result.json`)
  - [ ] 驗證 CLI 退出碼為 0（成功）
  - [ ] 驗證主控台輸出包含報表位置與成功摘要

- [ ] 實作失敗流程的端對端測試 (AC: 1, 2)
  - [ ] 測試無效規格檔案處理（語法錯誤、檔案不存在）
  - [ ] 測試無效流程檔案處理（缺少必要欄位、YAML 解析錯誤）
  - [ ] 測試 HTTP 呼叫失敗情境（連線失敗、逾時、404/500 錯誤）
  - [ ] 測試驗證失敗情境（狀態碼不符、Schema 驗證失敗、自訂規則失敗）
  - [ ] 驗證錯誤報表正確產生，包含失敗細節
  - [ ] 驗證 CLI 退出碼為 1（測試失敗）或 2（系統錯誤）
  - [ ] 驗證主控台輸出包含失敗計數與錯誤摘要

- [ ] 實作 MCP JSON-RPC 錯誤流程測試 (AC: 2)
  - [ ] 透過 `apps/mcp-server` 啟動 JSON-RPC 伺服器測試實例
  - [ ] 使用 `pnpm exec tsx apps/mcp-server/src/index.ts` 或 `execa` 呼叫對應指令模組，發送 `runFlow`、`listSpecs`、`getReport`
  - [ ] 驗證成功回應符合 JSON-RPC 2.0 規格（`jsonrpc`, `id`, `result`）
  - [ ] 驗證錯誤情境回傳 1500 系列錯誤碼與 `error.data` 詳細資訊
  - [ ] 確認 MCP 測試共用端對端測試框架與測試資料

- [ ] 實作認證流程的端對端測試 (AC: 1, 2)
  - [ ] 測試登入步驟與 Token 取得流程（整合 Story 2.3）
  - [ ] 測試 Token 自動注入後續請求 Header
  - [ ] 測試多命名空間 Token 管理
  - [ ] 測試 Token 失效或缺失的錯誤處理
  - [ ] 驗證認證事件正確記錄於日誌中

- [ ] 實作報表與日誌驗證測試 (AC: 1, 4)
  - [ ] 驗證報表檔案格式符合 JSON Schema（整合 Story 2.4）
  - [ ] 驗證報表內容完整性（executionId, steps, summary, config）
  - [ ] 驗證日誌檔案產生與格式（JSON Lines）
  - [ ] 驗證日誌包含完整步驟記錄（請求摘要、回應摘要、錯誤）
  - [ ] 驗證敏感資料正確遮罩（Token、密碼）
  - [ ] 驗證日誌輪替機制運作（若檔案超過大小限制）

- [ ] 實作效能與 NFR 驗證測試 (AC: 3)
  - [ ] 建立效能測試案例，模擬 20-30 步驟的測試流程
  - [ ] 驗證執行時間符合 NFR2 要求（≤ 60 秒）
  - [ ] 測試大型 OpenAPI 規格處理（≥100 endpoints）
  - [ ] 監控記憶體使用量，確保不超過合理範圍
  - [ ] 建立效能基準測試與回歸檢測機制
  - [ ] 整合 CI 環境執行效能測試

- [ ] 建立測試資料與模擬環境 (AC: 4)
  - [ ] 準備完整的測試 OpenAPI 規格檔案於 `specs/`
  - [ ] 準備多種測試流程 YAML 於 `flows/`（成功、失敗、認證、複雜流程）
  - [ ] 使用 nock 或 msw 建立 HTTP 模擬伺服器
  - [ ] 模擬各種 API 回應（成功、錯誤、逾時、認證）
  - [ ] 建立可重複使用的測試夾具（fixtures）
  - [ ] 建立根目錄 `specs/` 與 `flows/` 工作區目錄（若尚未存在），並與 `packages/testing/fixtures` 保持同步來源

- [ ] CI 整合與自動化 (AC: 3)
  - [ ] 建立 CI 測試腳本（`pnpm test:e2e` 或 `pnpm test:integration`）
  - [ ] 設定 CI 環境變數與測試配置
  - [ ] 整合效能測試到 CI 管線
  - [ ] 設定測試失敗時的錯誤報告機制
  - [ ] 建立測試覆蓋率報告與趨勢追蹤
  - [ ] 確保測試在 CI 環境穩定執行（避免 flaky tests）
  - [ ] 建立或更新 `.github/workflows/e2e.yml`（或等效 CI 定義）於 PR 流程執行 `pnpm test:e2e`
  - [ ] 在 CI 中紀錄端對端測試耗時與記憶體使用量，並對應 NFR2 ≤ 60 秒門檻

- [ ] 文件與範例更新 (AC: 4)
  - [ ] 更新測試策略文件，記錄端對端測試方法
  - [ ] 提供測試執行指南（本地與 CI）
  - [ ] 建立測試資料使用說明
  - [ ] 更新 README，說明如何執行端對端測試
  - [ ] 提供測試案例範例與最佳實踐

## Dev Notes

### Previous Story Insights

[Source: docs/stories/2.4.story.md - Dev Agent Record & QA Results]

- **Story 2.4 完成的基礎設施**：
  - ReportingIntegration、EnhancedStructuredLogger、ReportGenerator 等核心元件已建立
  - 完整的報表與日誌 JSON Schema 驗證機制
  - 非同步日誌寫入器、批次處理、日誌輪替機制
  - 整合測試範例於 `tests/integration/reporting-flow.spec.ts`

- **Story 2.3 認證架構**：
  - AuthenticationHandler 支援登入步驟與 Token 管理
  - 多命名空間 Token 儲存與自動注入
  - 認證事件日誌記錄（TOKEN_LOADED, TOKEN_INJECTED 等）

- **Story 2.1-2.2 執行引擎**：
  - HTTP Runner 使用 axios 支援所有 HTTP 方法
  - Validation Engine 支援狀態碼、Schema 與自訂規則驗證
  - 重試機制與錯誤處理

- **測試基礎設施已建立**：
  - 測試資料位於 `packages/testing/fixtures/`
  - 整合測試範例於 `tests/integration/`
  - 測試覆蓋率標準：單元 70%、整合 25%、端對端 5%

- **QA 階段發現的重點**：
  - 需注意異步操作正確處理（async/await vs .then().catch()）
  - 敏感資料遮罩需使用正則表達式支援更多欄位類型
  - 效能測試應包含 50 步驟並要求 10 秒內完成

### Technology Stack Requirements

[Source: docs/architecture/技術堆疊.md]

- **測試框架**: Vitest 1.6.0 - 端對端測試主要框架
- **HTTP 模擬**: nock 13.4.0 - 模擬外部 API 呼叫
- **CLI 執行**: execa（或類似工具）- 執行 CLI 指令並捕獲輸出
- **檔案系統**: Node.js 原生 fs 模組 - 驗證報表與日誌檔案產生
- **HTTP 客戶端**: axios 1.6.8 - 已整合於 HTTP Runner
- **Schema 驗證**: ajv 8.12.0 - 驗證報表與日誌格式
- **Language**: TypeScript 5.4.5 - 強型別測試程式碼
- **CLI/MCP 執行工具狀態**：目前根目錄 `package.json` 尚未安裝 `execa`，需於本故事實作時新增 devDependency（建議版本 ≥ 8.x）或同步更新測試框架改用既有 Node API。

### Data Models

[Source: docs/architecture/資料模型.md; docs/stories/2.4.story.md]

**ExecutionReport** - 流程執行報表（端對端測試需驗證）：
- 必要欄位：`executionId`, `flowId`, `startTime`, `endTime`, `duration`, `status`, `summary`, `steps`, `config`
- `summary` 包含：`totalSteps`, `successfulSteps`, `failedSteps`, `skippedSteps`
- `steps` 陣列包含每個步驟的執行結果

**StepResult** - 步驟執行結果：
- 必要欄位：`name`, `status`, `startTime`, `duration`, `request`, `response`
- `request` 包含：`method`, `url`, `headerHash`, `bodyHash`
- `response` 包含：`statusCode`, `success`, `validationResults`, `errorMessage`

**StructuredLogEntry** - 結構化日誌項目：
- 必要欄位：`timestamp`, `level`, `executionId`, `component`, `event`, `details`
- 事件代碼：`FLOW_START`, `FLOW_COMPLETE`, `STEP_START`, `STEP_COMPLETE`, `STEP_FAILURE`, `REPORT_GENERATED` 等

### Component Specifications

[Source: docs/architecture/系統元件.md; docs/architecture/原始碼結構.md]

**CLI Interface (`apps/cli/`)** - 測試目標主體：
- 入口點：`src/index.ts` 與 `bin/specpilot.ts`
- 指令處理：`src/commands/` - 處理 `run` 指令
- 適配器層：`src/adapters/` - 整合各套件功能

**Flow Orchestrator (`packages/core-flow/`)** - 核心執行引擎：
- EnhancedFlowOrchestrator - 協調流程執行與報表產生
- ReportingIntegration - 整合日誌與報表功能

**測試基礎設施 (`packages/testing/`)** - 測試輔助工具：
- `fixtures/specs/` - 測試用 OpenAPI 規格
- `fixtures/flows/` - 測試用 Flow YAML
- Factory 函式 - 建立測試資料

### File Locations

[Source: docs/architecture/原始碼結構.md; docs/architecture/測試策略.md]

- **端對端測試目錄**：`tests/e2e/` 或 `tests/integration/`
  - 檔案命名：`*.e2e.spec.ts` 或 `*.spec.ts`
  - 與單元測試（`*.test.ts`）區分

- **測試資料位置與同步策略**：
  - **主要測試資料來源**：`packages/testing/fixtures/specs/` 與 `packages/testing/fixtures/flows/`（單一真實來源）
  - **根目錄工作區**：`specs/` 與 `flows/`（供 CLI 執行與端對端測試使用）
  - **測試報表輸出**：`reports/` 或測試暫存目錄（`test-integration/`）
  - **同步策略**（建議）：
    - **方法 1（建議）**：使用符號連結（symlink）避免資料重複
      - `specs/` → `packages/testing/fixtures/specs/`
      - `flows/` → `packages/testing/fixtures/flows/`
    - **方法 2（替代）**：測試執行時從 fixtures 複製到根目錄（適用於無 symlink 支援的環境）
    - **注意**：若根目錄 `specs/`、`flows/` 已存在且非 symlink，需確認其內容與 fixtures 一致

- **整合測試範例**：
  - `tests/integration/reporting-flow.spec.ts` - 報表流程測試
  - `tests/integration/auth-flow.spec.ts` - 認證流程測試
  - `tests/integration/auth-config.spec.ts` - 認證配置測試

- **CLI 執行檔**：
  - `apps/cli/bin/specpilot.ts` - CLI 入口點
  - 或編譯後的執行檔

### Testing Strategy Requirements

[Source: docs/architecture/測試策略.md]

- **測試金字塔**：單元 60% / 整合 30% / 端對端 10%
  - 本故事專注於端對端測試（10%）

- **端對端測試特性**：
  - 使用本地測試環境執行典型流程
  - 無需複雜容器化設定
  - 使用 nock/msw 建立 mock server
  - 透過 execa 驗證 CLI/MCP

- **測試資料管理**：
  - `packages/testing/fixtures` 儲存樣本
  - 提供 factory 函式建立測試資料
  - 使用暫時資料夾並於測試後清理

- **測試標準**：
  - 遵守 AAA（Arrange, Act, Assert）模式
  - 目標覆蓋率 ≥ 80%（整體），關鍵模組 ≥ 85%
  - 測試後清理生成的報表與日誌檔案

- **持續測試**：
  - 本地執行：`pnpm test`、`pnpm test:integration`
  - CI/CD 整合（本故事重點）

### Technical Constraints

[Source: docs/architecture/程式撰寫規範.md]

- **命名慣例**：
  - 測試檔案使用 kebab-case
  - 整合/端對端測試：`*.spec.ts`
  - 單元測試：`*.test.ts`

- **TypeScript 嚴格模式**：
  - 測試程式碼也需符合 TypeScript 嚴格模式
  - 明確型別註解，避免 `any`

- **日誌規範**：
  - 測試中仍需使用 StructuredLogger（非 console.log）
  - 或使用測試專用的 mock logger

- **檔案操作**：
  - 使用 Node.js 原生 fs 模組
  - 測試後清理暫存檔案與目錄
  - 避免污染實際專案目錄

### NFR2 Performance Requirements

[Source: docs/prd/requirements.md - NFR2]

- **效能要求**：單一測試流程執行時間應在 1 分鐘以內
- **測試基準**：標準開發環境（4 核心 CPU、8 GB RAM、本地或等效 Docker）
- **本故事需驗證**：
  - 建立 20-30 步驟的效能測試流程
  - 自動化檢查執行時間 ≤ 60 秒
  - 整合 CI 環境執行效能測試
  - 監控記憶體使用量

### CLI Exit Codes & Error Handling

[Source: docs/architecture/錯誤處理策略.md; docs/prd/requirements.md]

- **退出碼規範**：
  - 0：全部成功
  - 1：測試失敗（至少一個步驟失敗）
  - 2：系統錯誤（規格載入失敗、流程解析失敗、配置錯誤等）

- **錯誤分類**（需測試）：
  - 組態錯誤（1501）：遺失/無效的組態檔案
  - 規格錯誤（1502）：無效的 OpenAPI 規格
  - 流程錯誤（1503）：YAML 語法/格式問題
  - 網路錯誤（1504-1505）：連線失敗與逾時
  - 驗證錯誤（1506）：Schema/自訂規則失敗
  - 認證錯誤（1507）：無效/過期的憑證

### Integration Points

- **整合 Story 2.1-2.4 所有功能**：
  - HTTP Runner（2.1）
  - Validation Engine（2.2）
  - Authentication Handler（2.3）
  - Reporting & Logging（2.4）

- **測試完整核心流程**：
  [Source: docs/architecture/核心流程.md]
  1. CLI 啟動與參數解析
  2. Config Service 讀取配置
  3. Spec Loader 載入並驗證 OpenAPI
  4. Flow Parser 解析 Flow YAML
  5. Flow Orchestrator 執行流程
  6. HTTP Execution Engine 發送請求
  7. Validation Engine 驗證回應
  8. Reporter 產生報表
  9. Structured Logger 記錄日誌
  10. CLI 輸出結果與退出碼

### Mock Server Setup

[Source: docs/architecture/測試策略.md; tests/integration/reporting-flow.spec.ts]

- **使用 nock 模擬 HTTP 呼叫**：
  - 模擬各種 API 回應（200, 400, 404, 500, 逾時）
  - 模擬登入端點回傳 JWT Token
  - 模擬需認證的端點驗證 Token

- **測試隔離**：
  - 每個測試案例獨立配置 nock
  - 測試後清理 nock 攔截器
  - 避免測試間互相干擾

### Test Data Examples

[Source: packages/testing/fixtures/]

- **現有測試資料**：
  - `specs/petstore.json` - 完整的 Pet Store API 規格
  - `specs/minimal.yaml` - 最小化測試規格
  - `specs/simple.json` - 簡單測試規格
  - `specs/invalid-schema.yaml` - 無效規格測試
  - `flows/user_crud.yaml` - CRUD 測試流程
  - `flows/minimal_flow.yaml` - 最小化流程
  - `flows/invalid_flow.yaml` - 無效流程測試

- **本故事需新增**：
  - 完整端對端測試流程 YAML（包含登入、認證、多步驟）
  - 效能測試用的大型流程 YAML（20-30 步驟）
  - 各種失敗情境的測試流程

### CI Integration Considerations

- **CI 環境特性**：
  - 可能較慢或資源受限
  - 需穩定的測試執行（避免 flaky tests）
  - 使用 mock server（非真實 API）

- **測試腳本**：
  - `pnpm test:e2e` 或 `pnpm test:integration`
  - 整合到現有的 `pnpm test` 流程

- **環境變數配置**：
  - `TEST_BASE_URL` - 測試 API 基礎 URL（預設：http://localhost:3000）
  - `TEST_TIMEOUT` - 測試逾時設定（預設：30000ms）
  - `CI` - CI 環境標記（由 CI 系統自動設定）
  - `MOCK_SERVER_ENABLED` - 是否使用 Mock server（預設：true）
  - `PERFORMANCE_THRESHOLD` - 效能測試閾值（預設：60000ms，對應 NFR2）
  - 測試環境的 baseUrl、port 等配置
  - CI 專用的效能測試閾值調整

### Test Environment Security

[Source: docs/architecture/安全性策略.md; 測試環境最佳實踐]

- **Mock Credentials 使用**：
  - 測試環境必須使用 mock credentials（如 `test-token-12345`、`test-user`）
  - 禁止使用真實生產環境 Token 或 API Key
  - 測試資料中的敏感欄位應使用假資料（如 `password: "test-password-123"`）

- **Mock Server 隔離**：
  - Mock server 僅監聽 localhost，不對外暴露
  - 使用 nock 的 HTTP 攔截機制，無需啟動真實伺服器
  - 確保測試不會意外呼叫生產環境 API

- **CI 環境變數安全**：
  - CI 環境變數不應包含敏感生產資料
  - 使用 CI 專用的測試憑證（如 GitHub Actions Secrets 中的 `TEST_TOKEN`）
  - 測試報表與日誌輸出應經過敏感資料遮罩（整合 Story 2.4 的遮罩機制）

- **測試資料管理**：
  - 測試後清理所有生成的暫存檔案與目錄
  - 避免在測試中寫入實際專案目錄（使用 `test-integration/` 暫存目錄）
  - 測試執行前驗證環境變數，確保未使用生產環境配置

## Testing

### Test File Locations

[Source: docs/architecture/測試策略.md]

- **端對端測試**：`tests/e2e/` 或 `tests/integration/`
- **測試資料**：`packages/testing/fixtures/`
- **測試輔助工具**：`packages/testing/utils/` 或 `tests/helpers/`

### Testing Standards

- **使用 Vitest 1.6.0 測試框架**
- **目標覆蓋率**：本故事主要建立端對端測試（佔整體測試的 10%）
- **遵守 AAA（Arrange, Act, Assert）模式**
- **測試隔離**：每個測試案例獨立配置與清理
- **測試後清理**：刪除生成的報表、日誌與暫存檔案

### Testing Requirements for This Story

- **CLI 執行測試**：使用 execa 或類似工具執行實際 CLI 指令
- **檔案系統驗證**：檢查報表與日誌檔案是否正確產生
- **退出碼驗證**：確認 CLI 退出碼符合規範（0/1/2）
- **主控台輸出驗證**：檢查 CLI 輸出是否包含預期訊息
- **報表格式驗證**：使用 ReportValidator 與 SchemaValidator 驗證
- **效能測試**：執行時間 ≤ 60 秒（NFR2）
- **Mock server**：使用 nock 模擬所有外部 API 呼叫
- **測試穩定性**：確保測試在 CI 環境穩定執行
- **MCP JSON-RPC 驗證**：於端對端測試中呼叫 MCP 伺服器，確認成功與錯誤回應均符合 JSON-RPC 2.0 與 1500 系列錯誤碼規範。
- **效能量測方法**：於測試中紀錄 `performance.now()`（或 `process.hrtime()`）與記憶體 `process.memoryUsage()`，並將結果輸出至測試報表以供 CI 判斷。

## Change Log

| Date       | Version | Description                                                                                              | Author                |
| ---------- | ------- | -------------------------------------------------------------------------------------------------------- | --------------------- |
| 2025-09-27 | v0.1    | 初稿建立                                                                                                 | Bob (Scrum Master)    |
| 2025-09-27 | v0.2    | 品質改進：新增測試環境安全性章節、明確環境變數清單、優化測試資料同步策略說明（基於 PO 驗證報告建議） | Sarah (Product Owner) |

## Dev Agent Record

### Agent Model Used

_待開發階段填入_

### Debug Log References

_待開發階段填入_

### Completion Notes

_待開發階段填入_

### File List

_待開發階段填入_

## QA Results

_待 QA 階段填入_
